import json
import os
import re
import sys
import textwrap
import time
import traceback
import warnings

import loguru
from prompt_toolkit.formatted_text import HTML
from prompt_toolkit.shortcuts import confirm
from rich.console import Console
from rich.spinner import Spinner

from sspentestlab.config.chat_config import ChatGPTConfig
from sspentestlab.prompts.prompt_class import SSPentestLabPrompts
from sspentestlab.utils.APIs.module_import import dynamic_import
from sspentestlab.utils.chatgpt import ChatGPT
from sspentestlab.utils.prompt_select import prompt_ask, prompt_select
from sspentestlab.utils.task_handler import (
    local_task_entry,
    localTaskCompleter,
    main_task_entry,
    mainTaskCompleter,
)

from sspentestlab.utils.report_generator import gpt_to_pdf
from sspentestlab.utils.script_code_command import analyze_text
from sspentestlab.utils.script_log_reader import read_command_log, read_history_log
from sspentestlab.utils.script_create_path import select_existing_command_log

from sspentestlab.utils.APIs.module_import import LangOllamaConfigClass
    
from sspentestlab.utils.APIs.rag_utils import LlamaIndexRAG




logger = loguru.logger

console = Console()
console.print("                                                                                  ", style= "bold green")
console.print("                                                                                  ", style= "bold green")
console.print("██████████████████████████████████████████████████████████████████████████████████", style= "bold green")
console.print("█─▄▄▄▄█─▄▄▄▄█▄─▄▄─█▄─▄▄─█▄─▀█▄─▄█─▄─▄─█▄─▄▄─█─▄▄▄▄█─▄─▄─█▀▀▀▀▀██▄─▄████▀▄─██▄─▄─▀█", style= "bold green")
console.print("█▄▄▄▄─█▄▄▄▄─██─▄▄▄██─▄█▀██─█▄▀─████─████─▄█▀█▄▄▄▄─███─███████████─██▀██─▀─███─▄─▀█", style= "bold green")
console.print("▀▄▄▄▄▄▀▄▄▄▄▄▀▄▄▄▀▀▀▄▄▄▄▄▀▄▄▄▀▀▄▄▀▀▄▄▄▀▀▄▄▄▄▄▀▄▄▄▄▄▀▀▄▄▄▀▀▀▀▀▀▀▀▀▄▄▄▄▄▀▄▄▀▄▄▀▄▄▄▄▀▀", style= "bold green")
console.print("                                                                                  ", style= "bold green")
console.print("                                                                                  ", style= "bold green")

json_unico_sesion = select_existing_command_log()
print(f"Selected registry file: {json_unico_sesion}")

class sspentestlab:
    postfix_options = {
        "tool": "The input content is from a security testing tool. You need to list down all the points that are interesting to you; you should summarize it as if you are reporting to a senior penetration tester for further guidance.\n",
        "user-comments": "The input content is from user comments and ideas.\n",
        "read-last-command": "",
        "read-history": "",
        "web": "The input content is from web pages. You need to summarize the readable-contents, and list down all the points that can be interesting for penetration testing.\n",
    }

    options_desc = {
        "tool": " - Paste the output of the security test tool used",
        "user-comments": " - Make a custom input",
        "read-last-command": " - Read last executed command",
        "read-history": " - Read whole conversation history",
        "web": " - Paste the relevant content of a web page",
    }



    def __init__(
        self,
        log_dir="./logs",
        reasoning_model="gpt-4-turbo",
        parsing_model="gpt-4-turbo",
        useAPI=True,
        # azure=False,
        use_langfuse_logging=False,
    ):
        """Initialize the tool."""
        
        self.log_dir = log_dir
        logger.add(sink=os.path.join(log_dir, "sspentestlab.log"))
        self.task_log = ({})  # the information that can be saved to continue in the next session
        self.useAPI = useAPI
        self.parsing_char_window = 16000  # the chunk size for parsing in # of chars
        # load the module
        reasoning_model_object = dynamic_import(reasoning_model, self.log_dir, use_langfuse_logging=use_langfuse_logging)
        generation_model_object = dynamic_import(reasoning_model, self.log_dir, use_langfuse_logging=use_langfuse_logging)
        parsing_model_object = dynamic_import(parsing_model, self.log_dir, use_langfuse_logging=use_langfuse_logging)
        self.parsingAgent = parsing_model_object
        self.generationAgent = generation_model_object
        self.reasoningAgent = reasoning_model_object
        self.prompts = SSPentestLabPrompts
        
        
        self.document_dir = "./RAG"
        self.persist_dir = "./storage"
        self.rag_system = LlamaIndexRAG(self.document_dir, self.persist_dir)

        
        # declare custom Console() to filter for <c> and </c> labels.
        self.console = Console()
        original_print = self.console.print
        def clean_command(command):
            return re.sub(r'</?c>', '', command).strip()
        def patched_print(*args, **kwargs):
            # Clean command if it’s a string.
            if 'text' in kwargs:
                kwargs['text'] = clean_command(kwargs['text'])
            elif args and isinstance(args[0], str):
                args = (clean_command(args[0]),) + args[1:]
            original_print(*args, **kwargs)
        # replace console.print with the patched version.
        self.console.print = patched_print

        self.spinner = Spinner("line", "Processing")
        self.test_generation_session_id = None
        self.test_reasoning_session_id = None
        self.input_parsing_session_id = None
        self.chat_count = 0
        self.step_reasoning = (
            None  # the response from the reasoning session for the current step.
        )
        self.history = {
            "user": [],
            "SSPentestLab": [],
            "reasoning": [],
            "input_parsing": [],
            "generation": [],
            "exception": [],
        }
        self.console.print(
            "Welcome to SSPentest-Lab, an automated penetration testing parser empowered by generative AI.", style="bold green",)
        self.console.print("The settings are: ")
        self.console.print(f" - parsing model: {parsing_model_object.name}", style="bold green")
        self.console.print(f" - reasoning model: {reasoning_model_object.name}", style="bold green")
        print()



    def log_conversation(self, source, text):
        """Append the conversation into the history file."""
        
        timestamp = time.time()
        if source not in self.history.keys():
            source = "exception"
        self.history[source].append((timestamp, text))



    def refresh_session(self):
        """Refresh/ Update session if necessary."""
        
        if self.useAPI:
            self.console.print("You're using API mode, so no need to refresh the session.")
            self.log_conversation("SSPentestLab","You're using API mode, so no need to refresh the session.",)
        else:
            self.console.print(
                "Please ensure that you put the curl command into `config/chatgpt_config_curl.txt`",
                style="bold green",
            )
            self.log_conversation(
                "SSPentestLab",
                "Please ensure that you put the curl command into `config/chatgpt_config_curl.txt`",
            )
            input("Press Enter to continue...")
            self.parsingAgent.refresh()
            self.reasoningAgent.refresh()
            self.console.print(
                "Session refreshed. If you receive the same session refresh request, please refresh the ChatGPT page and paste the new curl request again.",
                style="bold green",
            )
            self.log_conversation("sSPentestLabç", "Session refreshed.")
            return "Session refreshed."



    def _feed_init_prompts(self, loaded_session=None): 
        """Provide target for the tool to initialize, in case of loading a previous session it avoids setting a target and directly provides the old todo tree as initialization."""

        if loaded_session is not None:
            # Load previous session if specified
            init_loaded_session = loaded_session
            self.log_conversation("user", init_loaded_session)
            self.task_log["task description"] = init_loaded_session
            prefixed_init_description = self.prompts.load_todo + init_loaded_session

        else:
            while True:
                init_description = prompt_ask(
                    "Please provide me your target; web or target IP.\n> ",
                    multiline=False,
                )
                if init_description.strip():
                    break
                else:
                    self.console.print("Input cannot be blank. Please try again.", style="red")

            # log the conversation and process the task description
            self.log_conversation("user", init_description)
            self.task_log["task description"] = init_description
            prefixed_init_description = self.prompts.task_description + init_description

        retrieved_info = self.rag_system.query_index(prefixed_init_description)
        
        # debugging
        # self.console.print(f"[Feed Init Prompts] RAG Retrieved Info: ", style="sky_blue2")
        # self.console.print(retrieved_info, style="sky_blue1")

        # combine retrieved info with the task description for reasoning
        combined_description = f"{retrieved_info}\n\n{prefixed_init_description}"

        # send message to reasoning agent
        with self.console.status("[bold green] Constructing Initial Penetration Testing Tree...") as status:
            _reasoning_response = self.reasoningAgent.send_message(
                combined_description, self.test_reasoning_session_id)

        # send message to generation agent
        with self.console.status("[bold green] Generating Initial Task") as status:
            _generation_response = self.generationAgent.send_message(
                (self.prompts.todo_to_command + _reasoning_response), self.test_generation_session_id)

        # display the initial generation result
        response = _reasoning_response + "\n" + _generation_response
        self.console.print("SSPentestLab output: ", style="bold green")
        self.console.print(response)
        self.log_conversation("SSPentestLab", "SSPentestLab output:" + response)
        analyze_text(response, json_unico_sesion)



    def initialize(self, previous_session_data=None):
        """Initialize new sessions (generation, reasoning and parsing) at the beggining, and load previous sessions if specified previously."""
        
        with self.console.status(
            "[bold green] Initialize ChatGPT Sessions..."
        ) as status:
            try:
                (
                    text_0,
                    self.test_generation_session_id,
                ) = self.generationAgent.send_new_message(
                    self.prompts.generation_session_init,
                )
                (
                    text_1,
                    self.test_reasoning_session_id,
                ) = self.reasoningAgent.send_new_message(
                    self.prompts.reasoning_session_init
                )
                (
                    text_2,
                    self.input_parsing_session_id,
                ) = self.parsingAgent.send_new_message(
                    self.prompts.input_parsing_init
                )
            except Exception as e:
                self.console.print(f"Exception: {str(e)}", style="bold red")
                logger.error(e)
        self.console.print("- ChatGPT Sessions Initialized.", style="bold green")
        # load previous session.
        if previous_session_data is not None:
            self._feed_init_prompts(loaded_session=previous_session_data)
        else:
            self._feed_init_prompts(loaded_session=None)



    def input_parsing_handler(self, text, source=None) -> str:
        """Use textwrap to split inputs. Limit to 2000 token (8000 chars) for each input."""
        
        prefix = "Please summarize the following input. "
        if source is not None and source in self.postfix_options.keys():
            prefix += self.postfix_options[source]
        # replace all the newlines with spaces.
        text = text.replace("\r", " ").replace("\n", " ")
        # wrap the text.
        wrapped_text = textwrap.fill(text, 8000)
        wrapped_inputs = wrapped_text.split("\n")
        # send the inputs to openAI input_parsing_session and obtain the results.
        summarized_content = ""
        for wrapped_input in wrapped_inputs:
            word_limit = f"Please ensure that the input is less than {8000 / len(wrapped_inputs)} words.\n"
            summarized_content += self.parsingAgent.send_message(
                prefix + word_limit + wrapped_input, self.input_parsing_session_id)
        self.log_conversation("input_parsing", summarized_content)
        return summarized_content
    


    def reasoning_handler(self, text) -> str:
        """Summarize the contents if necessary, pass the information to reasoning_handler and obtain the results."""
        
        if len(text) > self.parsing_char_window:
            text = self.input_parsing_handler(text)
        
        # Include retrieved_info(RAG) in the prompt
        retrieved_info = self.rag_system.query_index(text)
        combined_text = f"{retrieved_info}\n\n{text}"
        
        # Update the PTT with the combined text
        _updated_ptt_response = self.reasoningAgent.send_message(
            self.prompts.process_results + combined_text, self.test_reasoning_session_id)

        _task_selection_response = self.reasoningAgent.send_message(
            self.prompts.process_results_task_selection, self.test_reasoning_session_id)

        response = _updated_ptt_response + _task_selection_response
        self.log_conversation("reasoning", response)
        return response
    
    def test_generation_handler(self, text) -> str:
        """Send the contents to openAI test_generation_session and obtain the results."""
        
        # include retrieved_info(RAG) in the prompt
        retrieved_info = self.rag_system.query_index(text)
        combined_text = f"{retrieved_info}\n\n{text}"
        
        response = self.generationAgent.send_message(combined_text, self.test_generation_session_id)
        self.log_conversation("generation", response)
        return response


    def report_generator_handler(self, text) -> str:
        """Send the contents to openAI test_generation_session and obtain the results needed to create the report."""
        
        response = self.generationAgent.send_message(
            text, self.test_generation_session_id)
        self.log_conversation("report", response)
        response = str(response)
        return response
    

    def local_input_handler(self) -> str:
        """Logic for the internal menu located inside the 'more' submenu, used exclusively for that submenu."""
        
        local_task_response = ""
        self.chat_count += 1
        local_request_option = local_task_entry()
        self.log_conversation("user", local_request_option)

        if local_request_option == "discuss":
            # request for user multi-line input.
            self.console.print("Please share your findings and questions with SSPentestLab.")
            self.log_conversation("SSPentestLab","Please share your findings and questions with SSPentestLab. (End with <shift + right-arrow>)",)
            user_input = prompt_ask("Your input: ", multiline=True)
            self.log_conversation("user", user_input)
            # provide the information to the reasoning session.
            with self.console.status("[bold green] SSPentestLab Thinking...") as status:
                local_task_response = self.test_generation_handler(
                    self.prompts.local_task_prefix + user_input)
            # print the results.
            self.console.print("SSPentestLab:\n", style="bold green")
            self.console.print(local_task_response + "\n", style="yellow")
            self.log_conversation("SSPentestLab", local_task_response)
            analyze_text(local_task_response, json_unico_sesion)

        elif local_request_option == "brainstorm":
            # request for user multi-line input.
            self.console.print("Please share your concerns and questions with SSPentestLab.")
            self.log_conversation("SSPentestLab","Please share your concerns and questions with SSPentestLab. End with <shift + right-arrow>)",)
            user_input = prompt_ask("Your input: ", multiline=True)
            self.log_conversation("user", user_input)
            # provide the information to the reasoning session.
            with self.console.status("[bold green] SSPentestLab Thinking...") as status:
                local_task_response = self.test_generation_handler(
                    self.prompts.local_task_brainstorm + user_input)
            # print the results.
            self.console.print("SSPentestLab:\n", style="bold green")
            self.console.print(local_task_response + "\n", style="yellow")
            self.log_conversation("SSPentestLab", local_task_response)
            analyze_text(local_task_response, json_unico_sesion)

        elif local_request_option == "continue":
            self.console.print("Exit the local task and continue the main task.")
            self.log_conversation("SSPentestLab", "Exit the local task and continue the main task.")
            local_task_response = "continue"

        return local_task_response



    def input_handler(self) -> str:
        """Internal logic for the different menu options."""
        
        self.chat_count += 1
        request_option = main_task_entry()
        self.log_conversation("user", request_option)
        # check if session is expired.
        if not self.useAPI:
            conversation_history = self.parsingAgent.get_conversation_history()
            while conversation_history is None:
                self.refresh_session()
                conversation_history = self.parsingAgent.get_conversation_history()
                
        elif request_option == "terminal":
            self.console.print("Write the commands you would like to execute and save in history.", style="bold white")
            response = input()
            return f'<term>{response}</term>'
        
        if request_option == "help":
             self.console.print(mainTaskCompleter().task_details)
             return " "

        if request_option == "next":
            # provide the information to input_parsing session and gives an option list for user to choose from.
            options = list(self.postfix_options.keys())
            opt_desc = list(self.options_desc.values())

            value_list = [(i, HTML(f'<style fg="cyan">{options[i]}</style><style fg="LightSeaGreen">{opt_desc[i]}</style>'),) for i in range(len(options))]
            
            source = prompt_select(title="Please choose the source of the information.", values=value_list)
            
            if source == 2:
                lectura_comando = read_command_log()
                user_input = f"The input content is from a security testing tool saved into a TXT file. You need to read and list down all the points that are interesting to you; you should summarize it as if you are reporting to a senior penetration tester for further guidance, the result is here: {lectura_comando}\n"
            
            elif source == 3:
                actual_historic = read_history_log(json_unico_sesion)
                user_input =  f"The input content is the history from various security testing tools saved into a JSON file. You need to read and list down all the points that are interesting to you; you should summarize it as if you are reporting to a senior penetration tester for further guidance, the result is here: {actual_historic}\n"
            
            else:
                self.console.print(
                    "Your input: (End with <shift + right-arrow>)", style="bold green"
                )
                user_input = prompt_ask("> ", multiline=True)
            self.log_conversation("user", f"Source: {options[int(source)]}" + "\n" + user_input)
            
            with self.console.status("[bold green] SSPentestLab Thinking...") as status:
                parsed_input = self.input_parsing_handler(
                    user_input, source=options[int(source)])
            # provide the summarized information to the reasoning session.
                reasoning_response = self.reasoning_handler(parsed_input)
                self.step_reasoning_response = reasoning_response

            # print the results
            self.console.print("Based on the analysis, the following tasks are recommended:", style="bold green",)
            self.console.print(reasoning_response + "\n")
            self.log_conversation("SSPentestLab","Based on the analysis, the following tasks are recommended:" + reasoning_response,)
            response = reasoning_response

        elif request_option == "more":
            # local task handler, gives an option list for user to choose from.
            self.console.print("You're entering the sub-task mode, nothing asked here will not be added to the main tree.", style="bold green",)
            while True:
                local_task_response = self.local_input_handler()
                if local_task_response == "continue":
                    response = "Welcome back to main tree :)"
                    # break the local task handler.
                    break

        elif request_option == "todo":
            self.log_conversation("user", 'todo')
            # ask the reasoning session to analyze the current situation, and list the top sub-tasks.
            with self.console.status("[bold green] SSPentestLab Thinking...") as status:
                reasoning_response = self.reasoning_handler(self.prompts.ask_todo)
                # pass the sub-tasks to the test_generation session.
                message = self.prompts.todo_to_command + "\n" + reasoning_response
                generation_response = self.test_generation_handler(message)
                # print the results.
            self.console.print("Based on the analysis, the following tasks are recommended:",mstyle="bold green")
            self.console.print(reasoning_response + "\n")
            response = reasoning_response
            self.log_conversation("SSPentestLab", reasoning_response)
            return response
        
        elif request_option == "discuss":
            # request for user multi-line input.
            self.console.print("Please share your thoughts/questions with SSPentestLab. (End with <shift + right-arrow>) ")
            self.log_conversation("SSPentestLab", "Please share your thoughts/questions with SSPentestLab.")
            user_input = prompt_ask("Your input: ", multiline=True)
            self.log_conversation("user", user_input)
            
            
            # pass the information to the reasoning session.
            with self.console.status("[bold green] SSPentestLab Thinking...") as status:
                response = self.reasoning_handler(self.prompts.discussion + user_input)
                            
            self.console.print("SSPentestLab:\n", style="bold green")
            self.console.print(response + "\n", style="yellow")
            self.log_conversation("SSPentestLab", response)
            
        
        elif request_option == "report":
            with self.console.status("[bold green] SSPentestLab is generating...\n") as status:
                historial = read_history_log(json_unico_sesion)
                reporte_temp = self.report_generator_handler(
                    self.prompts.report_generation + historial)
            # introduce file name and save to predefined file
            nombre_reporte = input("Choose report name: ")
            gpt_to_pdf(reporte_temp, nombre_reporte)
            self.log_conversation("SSPentestLab", "Report generated!!")
            response = f'{self.log_conversation("SSPentestLab", "Report generated!!")}'


        elif request_option == "quit":
            response = False
            self.console.print("Thank you for using SSPentestLab!", style="bold green")
            self.log_conversation("SSPentestLab", "Thank you for using SSPentestLab!")

        else:
            self.console.print("Please key in the correct options.", style="bold red")
            self.log_conversation("SSPentestLab", "Please key in the correct options.")
            response = "Please key in the correct options."
        return response  



    def save_session(self):
        """Save the current session. The session is saved in the directory './logs/sessions'."""
        
        directory = './logs/sessions/'
        
        # Ensure the directory exists
        if not os.path.exists(directory):
            os.makedirs(directory)
        
        self.console.print("Before you quit, you may want to save the current session.",style="bold green",)
        
        # Require a save name from the user. If not, use the current time as the save name.
        save_name = prompt_ask("Please enter the name of the current session. (Default with current timestamp)\n> ", multiline=False,)
        if save_name == "":
            save_name = str(time.time())
        
        # Append '.txt' extension to the save name
        save_path = os.path.join(directory, save_name + '.txt')
        
        with self.console.status("[bold green] SSPentestLab Saving...") as status:
            try:
                generation_response = self.test_generation_handler(self.prompts.export_todo)
            except Exception as e:  # catch all general exception.
                self.console.print(f"ExceptTTion: {str(e)}", style="bold red")
            
        # Save the session into the default folder with the specified name
        with open(save_path, "w") as f:
            if isinstance(generation_response, str):
                f.write(generation_response)
            else:
                f.write(str(generation_response))
                    
        self.console.print(f"The current session is saved as {save_path}", style="bold green")
        self.log_conversation("SSPentestLab", "Session saved!!")
        return



    def load_session(self) -> str:
        """Loads the specified file thats needed to load a previously saved session."""
        
        while True:
            continue_from_previous = confirm("Do you want to continue from previous session?")
            if continue_from_previous:
                # load the filenames from the save directory
                filenames = os.listdir('./logs/sessions/')
                directory = './logs/sessions/'
                
                if len(filenames) == 0:
                    print("No previous session found. Please start a new session.")
                    return None
                else:
                    print("Please select the previous session by its index (integer):")
                    for i, filename in enumerate(filenames):
                        print(f"{str(i)}. {filename}")
                    
                    while True:
                        try:
                            previous_testing_name = filenames[int(input("Please key in your option (integer): "))]
                            print(f"You selected: {previous_testing_name}")
                            break
                        except (ValueError, IndexError):
                            self.console.print("You input an invalid option. Please try again.", style="red")

            elif continue_from_previous is False:
                return None
            else:
                self.console.print("You input an invalid option. Please try again.", style="red")
                continue

            # load the previous session information
            if previous_testing_name is not None:
                try:
                    with open(
                        os.path.join(directory, previous_testing_name), "r") as f:
                        return f.read()
                except Exception as e:
                    print("Error when loading the previous session. The file name is not correct")
                    print(e)
                    return None


    def main(self):
        """The main function of SSPentest-Lab."""
        
        # initialize the backbone sessions and test the connection to openAI.
        loaded_session = self.load_session()
        self.initialize(previous_session_data=loaded_session)

        # enter the main loop.
        while True:
            try:
                try:
                    result = self.input_handler()
                    try:
                        analyze_text(result, json_unico_sesion)
                    except Exception as e:
                        pass
                    self.console.print("--------------------------------------------", style="bold white")
                    if not result:  # end the session
                        self.console.print("Thank you for your time, see you later!", style="bold white")
                        break
                except Exception as e:
                    self.console.print(f"Exception: {str(e)}", style="bold red")
                    break
            except Exception as e:  # catch all general exception.
                # log the exception.
                self.log_conversation("exception", str(e))
                # print the exception.
                self.console.print(f"Exception: {str(e)}", style="bold red")
                # add a more detailed debugging.
                exc_type, exc_obj, exc_tb = sys.exc_info()
                fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]
                self.console.print(
                    "Exception details are below. You may submit an issue on github and paste the error trace",
                    style="bold green",
                )
                self.console.print(exc_type, fname, exc_tb.tb_lineno)
                print(traceback.format_exc())
                # safely quit the session.
                break
        # log the session. Save self.history into a txt file based on timestamp.
        timestamp = time.time()
        log_name = f"SPentestLab_log_{str(timestamp)}.txt"
        # save it in the logs folder.
        log_path = os.path.join(self.log_dir, log_name)
        with open(log_path, "w") as f:
            json.dump(self.history, f)
        # save the sessions; continue from previous testing.
        self.save_session()

if __name__ == "__main__":
    SSPentestLab = sspentestlab()
    SSPentestLab.main()